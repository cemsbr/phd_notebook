{"Event":"SparkListenerLogStart","Spark Version":"1.5.1"}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"driver","Host":"10.2.2.71","Port":59203},"Maximum Memory":556038881,"Timestamp":1446793293895}
{"Event":"SparkListenerEnvironmentUpdate","JVM Information":{"Java Home":"/usr/lib/jvm/java-7-openjdk-amd64/jre","Java Version":"1.7.0_79 (Oracle Corporation)","Scala Version":"version 2.10.4"},"Spark Properties":{"spark.driver.host":"10.2.2.71","spark.eventLog.enabled":"true","spark.driver.port":"45970","spark.jars":"file:/home/hadoop/hibench/HiBench-972d87a/src/sparkbench/target/sparkbench-4.0-SNAPSHOT-MR2-spark1.4-jar-with-dependencies.jar","spark.app.name":"ScalaSort","spark.scheduler.mode":"FIFO","spark.driver.memory":"1G","spark.default.parallelism":"2","spark.executor.id":"driver","spark.submit.deployMode":"client","spark.master":"spark://hadoop0:7077","spark.executor.memory":"2G","spark.eventLog.dir":"file:///home/hadoop/exp07/outputs/spark-history","spark.fileserver.uri":"http://10.2.2.71:55039","spark.externalBlockStore.folderName":"spark-4de4d860-513f-4a18-818b-863099d243e3","spark.app.id":"app-20151106050133-0000","spark.sql.shuffle.partitions":"2"},"System Properties":{"java.io.tmpdir":"/tmp","line.separator":"\n","path.separator":":","sun.management.compiler":"HotSpot 64-Bit Tiered Compilers","SPARK_SUBMIT":"true","sun.cpu.endian":"little","java.specification.version":"1.7","java.vm.specification.name":"Java Virtual Machine Specification","java.vendor":"Oracle Corporation","java.vm.specification.version":"1.7","user.home":"/home/hadoop","file.encoding.pkg":"sun.io","sun.nio.ch.bugLevel":"","sun.arch.data.model":"64","sun.boot.library.path":"/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/amd64","user.dir":"/home/hadoop","java.library.path":"/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib","sun.cpu.isalist":"","os.arch":"amd64","java.vm.version":"24.79-b02","java.endorsed.dirs":"/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/endorsed","java.runtime.version":"1.7.0_79-b14","java.vm.info":"mixed mode","java.ext.dirs":"/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/ext:/usr/java/packages/lib/ext","java.runtime.name":"OpenJDK Runtime Environment","file.separator":"/","java.class.version":"51.0","java.specification.name":"Java Platform API Specification","sun.boot.class.path":"/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/resources.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/rt.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/jsse.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/jce.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/charsets.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/rhino.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/jfr.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/classes","file.encoding":"UTF-8","user.timezone":"America/Sao_Paulo","java.specification.vendor":"Oracle Corporation","sun.java.launcher":"SUN_STANDARD","os.version":"3.2.0-92-virtual","sun.os.patch.level":"unknown","java.vm.specification.vendor":"Oracle Corporation","user.country":"US","sun.jnu.encoding":"UTF-8","user.language":"en","java.vendor.url":"http://java.oracle.com/","java.awt.printerjob":"sun.print.PSPrinterJob","java.awt.graphicsenv":"sun.awt.X11GraphicsEnvironment","awt.toolkit":"sun.awt.X11.XToolkit","os.name":"Linux","java.vm.vendor":"Oracle Corporation","java.vendor.url.bug":"http://bugreport.sun.com/bugreport/","user.name":"hadoop","java.vm.name":"OpenJDK 64-Bit Server VM","sun.java.command":"org.apache.spark.deploy.SparkSubmit --master spark://hadoop0:7077 --properties-file /home/hadoop/hibench/HiBench-972d87a/report/sort/spark/scala/conf/sparkbench/spark.conf --class com.intel.sparkbench.sort.ScalaSort /home/hadoop/hibench/HiBench-972d87a/src/sparkbench/target/sparkbench-4.0-SNAPSHOT-MR2-spark1.4-jar-with-dependencies.jar hdfs://hadoop0/HiBench/Sort/Input hdfs://hadoop0/HiBench/Sort/Output","java.home":"/usr/lib/jvm/java-7-openjdk-amd64/jre","java.version":"1.7.0_79","sun.io.unicode.encoding":"UnicodeLittle"},"Classpath Entries":{"/home/hadoop/spark/spark/lib/datanucleus-api-jdo-3.2.6.jar":"System Classpath","/home/hadoop/spark/spark/lib/datanucleus-rdbms-3.2.9.jar":"System Classpath","http://10.2.2.71:55039/jars/sparkbench-4.0-SNAPSHOT-MR2-spark1.4-jar-with-dependencies.jar":"Added By User","/home/hadoop/spark/spark/lib/datanucleus-core-3.2.10.jar":"System Classpath","/home/hadoop/spark/spark/lib/spark-assembly-1.5.1-hadoop2.6.0.jar":"System Classpath","/home/hadoop/hadoop/hadoop/etc/hadoop/":"System Classpath","/home/hadoop/spark/spark/conf/":"System Classpath"}}
{"Event":"SparkListenerApplicationStart","App Name":"ScalaSort","App ID":"app-20151106050133-0000","Timestamp":1446793290159,"User":"hadoop"}
{"Event":"SparkListenerJobStart","Job ID":0,"Submission Time":1446793297129,"Stage Infos":[{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"map at ScalaSort.scala:47","Number of Tasks":9,"RDD Info":[{"RDD ID":3,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2\",\"name\":\"map\"}","Parent IDs":[2],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":9,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":0,"Name":"hdfs://hadoop0/HiBench/Sort/Input","Scope":"{\"id\":\"0\",\"name\":\"sequenceFile\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":9,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":1,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"0\",\"name\":\"sequenceFile\"}","Parent IDs":[0],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":9,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":2,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1\",\"name\":\"map\"}","Parent IDs":[1],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":9,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.map(RDD.scala:313)\ncom.intel.sparkbench.sort.ScalaSort$.main(ScalaSort.scala:47)\ncom.intel.sparkbench.sort.ScalaSort.main(ScalaSort.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},{"Stage ID":1,"Stage Attempt ID":0,"Stage Name":"saveAsHadoopFile at IOCommon.scala:64","Number of Tasks":1,"RDD Info":[{"RDD ID":6,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"4\",\"name\":\"map\"}","Parent IDs":[5],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":5,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"3\",\"name\":\"map\"}","Parent IDs":[4],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":4,"Name":"ShuffledRDD","Parent IDs":[3],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[0],"Details":"org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:896)\ncom.intel.sparkbench.IOCommon.save(IOCommon.scala:64)\ncom.intel.sparkbench.IOCommon.save(IOCommon.scala:74)\ncom.intel.sparkbench.sort.ScalaSort$.main(ScalaSort.scala:51)\ncom.intel.sparkbench.sort.ScalaSort.main(ScalaSort.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[0,1],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"5\",\"name\":\"saveAsHadoopFile\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"map at ScalaSort.scala:47","Number of Tasks":9,"RDD Info":[{"RDD ID":3,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2\",\"name\":\"map\"}","Parent IDs":[2],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":9,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":0,"Name":"hdfs://hadoop0/HiBench/Sort/Input","Scope":"{\"id\":\"0\",\"name\":\"sequenceFile\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":9,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":1,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"0\",\"name\":\"sequenceFile\"}","Parent IDs":[0],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":9,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":2,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1\",\"name\":\"map\"}","Parent IDs":[1],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":9,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.map(RDD.scala:313)\ncom.intel.sparkbench.sort.ScalaSort$.main(ScalaSort.scala:47)\ncom.intel.sparkbench.sort.ScalaSort.main(ScalaSort.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1446793297208,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"5\",\"name\":\"saveAsHadoopFile\"}"}}
{"Event":"SparkListenerExecutorAdded","Timestamp":1446793297887,"Executor ID":"0","Executor Info":{"Host":"10.2.0.201","Total Cores":2,"Log Urls":{"stdout":"http://10.2.0.201:8081/logPage/?appId=app-20151106050133-0000&executorId=0&logType=stdout","stderr":"http://10.2.0.201:8081/logPage/?appId=app-20151106050133-0000&executorId=0&logType=stderr"}}}
{"Event":"SparkListenerTaskStart","Stage ID":0,"Stage Attempt ID":0,"Task Info":{"Task ID":0,"Index":0,"Attempt":0,"Launch Time":1446793297900,"Executor ID":"0","Host":"10.2.0.201","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":0,"Stage Attempt ID":0,"Task Info":{"Task ID":1,"Index":1,"Attempt":0,"Launch Time":1446793297922,"Executor ID":"0","Host":"10.2.0.201","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"0","Host":"10.2.0.201","Port":33626},"Maximum Memory":1111794647,"Timestamp":1446793298201}
{"Event":"SparkListenerTaskStart","Stage ID":0,"Stage Attempt ID":0,"Task Info":{"Task ID":2,"Index":2,"Attempt":0,"Launch Time":1446793306806,"Executor ID":"0","Host":"10.2.0.201","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":0,"Stage Attempt ID":0,"Task Info":{"Task ID":3,"Index":3,"Attempt":0,"Launch Time":1446793306844,"Executor ID":"0","Host":"10.2.0.201","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":0,"Stage Attempt ID":0,"Task Type":"ShuffleMapTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":1,"Index":1,"Attempt":0,"Launch Time":1446793297922,"Executor ID":"0","Host":"10.2.0.201","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1446793306847,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.2.0.201","Executor Deserialize Time":1504,"Executor Run Time":6947,"Result Size":2250,"JVM GC Time":108,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Write Metrics":{"Shuffle Bytes Written":60694582,"Shuffle Write Time":336513648,"Shuffle Records Written":199166},"Input Metrics":{"Data Read Method":"Hadoop","Bytes Read":134218639,"Records Read":199166}}}
{"Event":"SparkListenerTaskEnd","Stage ID":0,"Stage Attempt ID":0,"Task Type":"ShuffleMapTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":0,"Index":0,"Attempt":0,"Launch Time":1446793297900,"Executor ID":"0","Host":"10.2.0.201","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1446793306857,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.2.0.201","Executor Deserialize Time":1513,"Executor Run Time":6999,"Result Size":2250,"JVM GC Time":108,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Write Metrics":{"Shuffle Bytes Written":60716067,"Shuffle Write Time":331418890,"Shuffle Records Written":199397},"Input Metrics":{"Data Read Method":"Hadoop","Bytes Read":134220610,"Records Read":199397}}}
{"Event":"SparkListenerTaskStart","Stage ID":0,"Stage Attempt ID":0,"Task Info":{"Task ID":4,"Index":4,"Attempt":0,"Launch Time":1446793311119,"Executor ID":"0","Host":"10.2.0.201","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":0,"Stage Attempt ID":0,"Task Info":{"Task ID":5,"Index":5,"Attempt":0,"Launch Time":1446793311127,"Executor ID":"0","Host":"10.2.0.201","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":0,"Stage Attempt ID":0,"Task Type":"ShuffleMapTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":3,"Index":3,"Attempt":0,"Launch Time":1446793306844,"Executor ID":"0","Host":"10.2.0.201","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1446793311135,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.2.0.201","Executor Deserialize Time":9,"Executor Run Time":4252,"Result Size":2250,"JVM GC Time":103,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Write Metrics":{"Shuffle Bytes Written":60690349,"Shuffle Write Time":310016397,"Shuffle Records Written":199612},"Input Metrics":{"Data Read Method":"Hadoop","Bytes Read":134218449,"Records Read":199612}}}
{"Event":"SparkListenerTaskEnd","Stage ID":0,"Stage Attempt ID":0,"Task Type":"ShuffleMapTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":2,"Index":2,"Attempt":0,"Launch Time":1446793306806,"Executor ID":"0","Host":"10.2.0.201","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1446793311138,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.2.0.201","Executor Deserialize Time":11,"Executor Run Time":4286,"Result Size":2250,"JVM GC Time":103,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Write Metrics":{"Shuffle Bytes Written":60684122,"Shuffle Write Time":321181839,"Shuffle Records Written":199368},"Input Metrics":{"Data Read Method":"Hadoop","Bytes Read":134219318,"Records Read":199368}}}
{"Event":"SparkListenerTaskStart","Stage ID":0,"Stage Attempt ID":0,"Task Info":{"Task ID":6,"Index":6,"Attempt":0,"Launch Time":1446793315282,"Executor ID":"0","Host":"10.2.0.201","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":0,"Stage Attempt ID":0,"Task Type":"ShuffleMapTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":4,"Index":4,"Attempt":0,"Launch Time":1446793311119,"Executor ID":"0","Host":"10.2.0.201","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1446793315292,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.2.0.201","Executor Deserialize Time":9,"Executor Run Time":4135,"Result Size":2250,"JVM GC Time":107,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Write Metrics":{"Shuffle Bytes Written":60687299,"Shuffle Write Time":327209111,"Shuffle Records Written":199443},"Input Metrics":{"Data Read Method":"Hadoop","Bytes Read":134220649,"Records Read":199443}}}
{"Event":"SparkListenerTaskStart","Stage ID":0,"Stage Attempt ID":0,"Task Info":{"Task ID":7,"Index":7,"Attempt":0,"Launch Time":1446793315367,"Executor ID":"0","Host":"10.2.0.201","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":0,"Stage Attempt ID":0,"Task Type":"ShuffleMapTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":5,"Index":5,"Attempt":0,"Launch Time":1446793311127,"Executor ID":"0","Host":"10.2.0.201","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1446793315371,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.2.0.201","Executor Deserialize Time":8,"Executor Run Time":4218,"Result Size":2250,"JVM GC Time":107,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Write Metrics":{"Shuffle Bytes Written":60679928,"Shuffle Write Time":317886408,"Shuffle Records Written":199813},"Input Metrics":{"Data Read Method":"Hadoop","Bytes Read":134219725,"Records Read":199813}}}
{"Event":"SparkListenerTaskStart","Stage ID":0,"Stage Attempt ID":0,"Task Info":{"Task ID":8,"Index":8,"Attempt":0,"Launch Time":1446793319847,"Executor ID":"0","Host":"10.2.0.201","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":0,"Stage Attempt ID":0,"Task Type":"ShuffleMapTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":6,"Index":6,"Attempt":0,"Launch Time":1446793315282,"Executor ID":"0","Host":"10.2.0.201","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1446793319855,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.2.0.201","Executor Deserialize Time":9,"Executor Run Time":4536,"Result Size":2250,"JVM GC Time":6,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Write Metrics":{"Shuffle Bytes Written":60689903,"Shuffle Write Time":278499763,"Shuffle Records Written":199376},"Input Metrics":{"Data Read Method":"Hadoop","Bytes Read":134219833,"Records Read":199376}}}
{"Event":"SparkListenerTaskEnd","Stage ID":0,"Stage Attempt ID":0,"Task Type":"ShuffleMapTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":7,"Index":7,"Attempt":0,"Launch Time":1446793315367,"Executor ID":"0","Host":"10.2.0.201","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1446793319982,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.2.0.201","Executor Deserialize Time":9,"Executor Run Time":4584,"Result Size":2250,"JVM GC Time":6,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Write Metrics":{"Shuffle Bytes Written":60690008,"Shuffle Write Time":296745322,"Shuffle Records Written":199406},"Input Metrics":{"Data Read Method":"Hadoop","Bytes Read":134219831,"Records Read":199406}}}
{"Event":"SparkListenerTaskEnd","Stage ID":0,"Stage Attempt ID":0,"Task Type":"ShuffleMapTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":8,"Index":8,"Attempt":0,"Launch Time":1446793319847,"Executor ID":"0","Host":"10.2.0.201","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1446793320591,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.2.0.201","Executor Deserialize Time":8,"Executor Run Time":714,"Result Size":2250,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Write Metrics":{"Shuffle Bytes Written":12880233,"Shuffle Write Time":57660997,"Shuffle Records Written":42323},"Input Metrics":{"Data Read Method":"Hadoop","Bytes Read":28485236,"Records Read":42323}}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"map at ScalaSort.scala:47","Number of Tasks":9,"RDD Info":[{"RDD ID":3,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2\",\"name\":\"map\"}","Parent IDs":[2],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":9,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":0,"Name":"hdfs://hadoop0/HiBench/Sort/Input","Scope":"{\"id\":\"0\",\"name\":\"sequenceFile\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":9,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":1,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"0\",\"name\":\"sequenceFile\"}","Parent IDs":[0],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":9,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":2,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1\",\"name\":\"map\"}","Parent IDs":[1],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":9,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.map(RDD.scala:313)\ncom.intel.sparkbench.sort.ScalaSort$.main(ScalaSort.scala:47)\ncom.intel.sparkbench.sort.ScalaSort.main(ScalaSort.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1446793297208,"Completion Time":1446793320593,"Accumulables":[]}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":1,"Stage Attempt ID":0,"Stage Name":"saveAsHadoopFile at IOCommon.scala:64","Number of Tasks":1,"RDD Info":[{"RDD ID":6,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"4\",\"name\":\"map\"}","Parent IDs":[5],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":5,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"3\",\"name\":\"map\"}","Parent IDs":[4],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":4,"Name":"ShuffledRDD","Parent IDs":[3],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[0],"Details":"org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:896)\ncom.intel.sparkbench.IOCommon.save(IOCommon.scala:64)\ncom.intel.sparkbench.IOCommon.save(IOCommon.scala:74)\ncom.intel.sparkbench.sort.ScalaSort$.main(ScalaSort.scala:51)\ncom.intel.sparkbench.sort.ScalaSort.main(ScalaSort.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"5\",\"name\":\"saveAsHadoopFile\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":1,"Stage Attempt ID":0,"Task Info":{"Task ID":9,"Index":0,"Attempt":0,"Launch Time":1446793320875,"Executor ID":"0","Host":"10.2.0.201","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":1,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":9,"Index":0,"Attempt":0,"Launch Time":1446793320875,"Executor ID":"0","Host":"10.2.0.201","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1446793375599,"Failed":false,"Accumulables":[{"ID":2,"Name":"peakExecutionMemory","Update":"353138376","Value":"353138376"}]},"Task Metrics":{"Host Name":"10.2.0.201","Executor Deserialize Time":137,"Executor Run Time":54561,"Result Size":2081,"JVM GC Time":4095,"Result Serialization Time":1,"Memory Bytes Spilled":1729335961,"Disk Bytes Spilled":413884947,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":9,"Fetch Wait Time":1,"Remote Bytes Read":0,"Local Bytes Read":498412491,"Total Records Read":1637904},"Output Metrics":{"Data Write Method":"Hadoop","Bytes Written":977500046,"Records Written":1637904}}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":1,"Stage Attempt ID":0,"Stage Name":"saveAsHadoopFile at IOCommon.scala:64","Number of Tasks":1,"RDD Info":[{"RDD ID":6,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"4\",\"name\":\"map\"}","Parent IDs":[5],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":5,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"3\",\"name\":\"map\"}","Parent IDs":[4],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":4,"Name":"ShuffledRDD","Parent IDs":[3],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[0],"Details":"org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:896)\ncom.intel.sparkbench.IOCommon.save(IOCommon.scala:64)\ncom.intel.sparkbench.IOCommon.save(IOCommon.scala:74)\ncom.intel.sparkbench.sort.ScalaSort$.main(ScalaSort.scala:51)\ncom.intel.sparkbench.sort.ScalaSort.main(ScalaSort.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1446793320874,"Completion Time":1446793375602,"Accumulables":[{"ID":2,"Name":"peakExecutionMemory","Value":"353138376"}]}}
{"Event":"SparkListenerJobEnd","Job ID":0,"Completion Time":1446793375611,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerApplicationEnd","Timestamp":1446793375703}
