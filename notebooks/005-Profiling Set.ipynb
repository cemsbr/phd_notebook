{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Predicting target set using profiling set only</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from inc.notebook005 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One set of features for all applications\n",
    "\n",
    "For each feature set and for each application, we train the model with the profiling set using cross validation and measure RMSE for the both the profiling validation set and target (test) set. Then, we plot the results for two feature sets chosen by the profiling validation results. The first feature set has the minimum RMSE mean of all applications and the second one has the minimum RMSE maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictor = Predictor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Mean RMSE: input/workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = [('input/workers', lambda df: df.input/df.workers)]\n",
    "predictor.set_features(features)\n",
    "predictor.print_rmse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_all(predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Max RMSE: log(input), log(workers), y = log(duration_ms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictor.use_log = True\n",
    "features = [('log(input)', lambda df: np.log2(df.input)),\n",
    "            ('log(workers)', lambda df: np.log2(df.workers))]\n",
    "predictor.set_features(features)\n",
    "predictor.print_rmse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_all(predictor)\n",
    "predictor.use_log = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outros testados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### log(input/workers), y = log(duration_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictor.use_log = True\n",
    "features = [('log(input/workers)', lambda df: np.log2(df.input/df.workers))]\n",
    "predictor.set_features(features)\n",
    "predictor.print_rmse()\n",
    "predictor.use_log = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input/workers, input, workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = [('input', lambda df: df.input),\n",
    "            ('workers', lambda df: df.workers),\n",
    "            ('input/workers', lambda df: df.input/df.workers)]\n",
    "predictor.set_features(features)\n",
    "predictor.print_rmse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input, workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = [('input', lambda df: df.input),\n",
    "            ('workers', lambda df: df.workers)]\n",
    "predictor.set_features(features)\n",
    "predictor.print_rmse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### log(input)/log(workers), y = log(duration_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictor.use_log = True\n",
    "features = [('log(input)/log(workers)', lambda df: np.log2(df.input - df.workers))]\n",
    "predictor.set_features(features)\n",
    "predictor.print_rmse()\n",
    "predictor.use_log = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The prediction using *input/workers* has high errors for the biggest target input size of both HB Sort and K-means. In contrast, when using *log(input)* and *log(workers)* to predict *log(duration)*, there are high errors for the Wikipedia app, a bit lower errors for HB Sort and significantly better results for HB K-means. None of the tested feature sets leads to good results for all applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple feature sets for each application\n",
    "\n",
    "Now, for each application, we choose the best feature set for the profiling set (using cross validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_sets = (\n",
    "    False,  # do not use log for makespan\n",
    "    ('input/workers', lambda df: df.input/df.workers)\n",
    "),(\n",
    "    True,  # predict log(makespan)\n",
    "    ('log(input)', lambda df: np.log2(df.input)),\n",
    "    ('log(workers)', lambda df: np.log2(df.workers))\n",
    "),(\n",
    "    False,  # do not use log for makespan\n",
    "    ('input', lambda df: df.input),\n",
    "    ('workers', lambda df: df.workers)\n",
    "),(\n",
    "    False,  # do not use log for makespan\n",
    "    ('input', lambda df: df.input),\n",
    "    ('workers', lambda df: df.workers),\n",
    "    ('input/workers', lambda df: df.input/df.workers)\n",
    "),(\n",
    "    True,  # predict log(makespan)\n",
    "    ('log(input/workers)', lambda df: np.log2(df.input/df.workers))\n",
    "),(\n",
    "    True,  # predict log(makespan)\n",
    "    ('log(input)/log(workers)', lambda df: np.log2(df.input - df.workers))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluate_feature_sets(feature_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The best feature set for the profiling set is not the best one for the target set. For example, in HB K-means, the best features for the profiling set is *input*, *workers*, *input/workers*, but its RMSE when predicting the target set is very high (125.01 sec)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
